# DevGenAI-Oct-2025


## Class evaluation
- Go to [aws.training](https://www.aws.training/)
- Click sign in, log in with the same account you used to access the lab and course materials
- Then go on the top right to My Account, then transcript, click on the Archived section (direct link [https://www.aws.training/Account/Transcript/Archived](https://www.aws.training/Account/Transcript/Archived)
- You should see the class, with a button to evaluate

## Contact details
- email: renatoalmeidamartins@gmail.com
- [Linkedin profile](https://www.linkedin.com/in/renatodealmeidamartins/)

# Class links
- [Access to lab and course materials](https://us-east-1.student.classrooms.aws.training/class/ilt%23gqFdeYYEWC3APQa9JXEQ5G)
- [Direct meeting link](https://awsvirtual.webex.com/awsvirtual/j.php?MTID=m5ac9d1b25ec41fa1322f4a1ab7a11c55)
- [Ideally, access the meetings through your transcript at classrooms.aws.training](https://classrooms.aws.training)

# Learning courses
- [Technical essentials](https://skillbuilder.aws/learn/K8C2FNZM6X/aws-technical-essentials/N7Q3SXQCDY)
- [Skill builder](https://skillbuilder.aws/learn)
- [Skill builder subscriptions](https://skillbuilder.aws/subscriptions)
- [Cloud quest for Gen AI practitioner](https://skillbuilder.aws/learn/5YB3FCEE1H/aws-cloud-quest-generative-ai-practitioner/26A81MG83V)

# Day 1 links
- [Neural network zoo](https://www.asimovinstitute.org/neural-network-zoo/)
- [Sagemaker's built-in algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)
- [AI winter](https://en.wikipedia.org/wiki/AI_winter)
- [Transformer architecture](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/)
- [Llama model leaked on 4chan](https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse)
- [Open weight models from OpenAI supported on Bedrock](https://aws.amazon.com/blogs/aws/openai-open-weight-models-now-available-on-aws/)
- [Clean code, a handbook of agile software craftmanship - advocates that clean code needs very limited comments](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)
- [Customizing models through - continued pre-training, fine-tuning and distillation](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html)
- [Sagemaker Clarify for model explainability - it excels at traditional ML, but there's also features "bedrock evaluations" to assess GenAI models](https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-explainability.html)
- [Sagemaker model monitor - creates benchamrks and, at chosen intervals, reevaluate the model against the baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)
- [Bedrock AgentCore is now generally available - building blocks for creating agents](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-is-now-generally-available/)
- [Bedrock supports API keys since July 2025](https://aws.amazon.com/blogs/machine-learning/accelerate-ai-development-with-amazon-bedrock-api-keys/)
- [bedrock-runtime, a single API for all model invoking operations. Basically, has 2 methods: invoke, converse (and their streaming variants)](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Operations_Amazon_Bedrock_Runtime.html)
- [Shared responsibility model](https://aws.amazon.com/compliance/shared-responsibility-model/)
- [Bedrock quotas](docs.aws.amazon.com/general/latest/gr/bedrock.html)
- [Bedrock pricing, typically pay-as-you-go (input and output tokens)](https://aws.amazon.com/bedrock/pricing/)
- [Bedrock provisioned throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html)
- [Bedrock no longer requires requesting model approval](https://aws.amazon.com/blogs/security/simplified-amazon-bedrock-model-access/)
- [Unsupervised vs supervised learning](https://aws.amazon.com/compare/the-difference-between-machine-learning-supervised-and-unsupervised/)
- [Supervised, unsupervised and reinforcement learning explained](https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html)
- [Diffusion models, approach to generate images](https://ommer-lab.com/research/latent-diffusion-models/)
- [Prompt components](https://docs.aws.amazon.com/bedrock/latest/userguide/design-a-prompt.html)
- [Prompt guidelines for different models](https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html)
- [Prompt design for Claude 3 - already obsolete, but the idea that you can optimize for a specific model family remains](https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/)
- [Prompt engineering ideas on AWS](https://aws.amazon.com/what-is/prompt-engineering/)
- [Converse API from bedrock-runtime, standardize on the inference parameter names](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html)
- [Announcement of the Converse API availability](https://aws.amazon.com/about-aws/whats-new/2024/05/amazon-bedrock-new-converse-api/)
- Security aspects of prompting
  - [Hacking LLM-driven robots](https://blog.seas.upenn.edu/penn-engineering-research-discovers-critical-vulnerabilities-in-ai-enabled-robots-to-increase-safety-and-security)
  - [GenAI threats](https://unit42.paloaltonetworks.com/new-frontier-of-genai-threats-a-comprehensive-guide-to-prompt-attacks/)
  - [GenAI OWASP](https://genai.owasp.org/)
  - [Mitigation strategies for GenAI attacks](https://www.youtube.com/watch?v=ewxCqXYoz4A)
  - [Tool for jailbreaking models](https://www.cyberark.com/resources/threat-research-blog/jailbreaking-every-llm-with-one-simple-click)
  - [Research about reducing models' attack surface](https://arxiv.org/abs/2410.15236)

# Day 2 links
- [OpenSearch as a vector database](https://aws.amazon.com/blogs/big-data/amazon-opensearch-services-vector-database-capabilities-explained/)
- [Faiss, an open source vector database from Facebook](https://github.com/facebookresearch/faiss)
- [Prescriptive guidance about vector databases for RAG](https://docs.aws.amazon.com/prescriptive-guidance/latest/choosing-an-aws-vector-database-for-rag-use-cases/introduction.html)
- [Features supported (input/output modalities, model-id, ...) for all models supported by Bedrock, with a link to their additional details and inference parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html)
- [Inference parameters for Bedrock models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html)
- [Langchain repo](https://python.langchain.com/docs/integrations/chat/)
- [Langchain documentation](https://docs.langchain.com/oss/python/langchain/overview)
- Relevant classes used in the tasks:
  - Task 1b
    - PrompTemplate, derived from [prompts](https://python.langchain.com/api_reference/core/prompts.html)
    - ChatBedrock, one of the multiple [Chat Models](https://python.langchain.com/docs/integrations/chat/) available
  - Task 2b
    - Creates a class that implements retry/backoff. Important to know that AWS SDKs have this [functionality built-in](https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html)
    - Calls a function to count tokens, [get_num_tokens](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.infino_callback.get_num_tokens.html), which is based on the documentation from [this OpenAI notebook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
    - Uses a text splitter. Multiple are available in langchain. More info [here](https://python.langchain.com/docs/concepts/text_splitters/)
    - Creates a chain to do summarization, using [load_summarize_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.summarize.chain.load_summarize_chain.html)
  - Task 3 doesn't use Langchain
  - Task 4
    - chat history through [InMemoryChatMessageHistory](https://python.langchain.com/api_reference/core/chat_history/langchain_core.chat_history.InMemoryChatMessageHistory.html) class
    - Does some RAG by loading a FAISS vector store, based on the implementation in [this blog article](https://aws.amazon.com/blogs/machine-learning/deploy-rag-applications-on-amazon-sagemaker-jumpstart-using-faiss/)
  - Task 5, doesn't use Langchain
  - Task 6
    - Based on the [ReAct framework](https://www.promptingguide.ai/techniques/react), defines agents
    - Agents are based on tools and [LangGraph](https://docs.langchain.com/oss/python/langgraph/overview)
    - [ReAct in the promptingguide](https://www.promptingguide.ai/techniques/react)
- [PromptingGuide.ai](https://www.promptingguide.ai/), a really good site talking about prompt engineering concepts

# Day "3"  links
- This standard for prompts was used in the Jam, so relevant to add here the [COSTAR - Context, Objective, Style, Tone, Audience, Response](https://aws.amazon.com/blogs/machine-learning/implementing-advanced-prompt-engineering-with-amazon-bedrock/) pattern
- [Gen AI Developer professional exam is coming, probably live early 2026](https://aws.amazon.com/certification/certified-generative-ai-developer-professional/)
- [MCP - Model Context Protocol,  an open protocol that enables seamless integration between LLM applications and external data sources and tools](https://modelcontextprotocol.io/)
- [List of MCP servers](https://github.com/modelcontextprotocol/servers)
- [A2A, the Agent2Agent (A2A) Protocol, an open standard designed to enable seamless communication and collaboration between AI agents](https://a2a-protocol.org/latest/)
- [Using the converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-examples.html)
